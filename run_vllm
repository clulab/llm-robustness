import json
import copy
import torch 
import os
from vllm import LLM, SamplingParams

#Qwen/Qwen3-0.6B

model_input_text = 'Can you tell me what 4 + 4 is?'

model = LLM(
    model = "Qwen/Qwen2.5-VL-3B-Instruct" , seed =1
)
sampling_params = SamplingParams(n=1, temperature=0, max_tokens=100, stop=["\n"])


output =model.generate(model_input_text, sampling_params =sampling_params)

outputs =output[0].outputs[0].text

print(outputs)